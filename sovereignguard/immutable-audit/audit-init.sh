#!/bin/bash
# SovereignGuard - Immutable Audit Setup
# Phase 5: Blockchain-Anchored Audit Logs
# Addresses exposures: #9, #10, #22, #23, #27

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOG_FILE="${SCRIPT_DIR}/audit-init.log"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    local level="$1"
    shift
    local msg="$*"
    local timestamp
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo -e "${timestamp} [${level}] ${msg}" | tee -a "$LOG_FILE"
}

info() { log "${BLUE}INFO${NC}" "$@"; }
warn() { log "${YELLOW}WARN${NC}" "$@"; }
error() { log "${RED}ERROR${NC}" "$@"; }
success() { log "${GREEN}SUCCESS${NC}" "$@"; }

# Create audit configuration
create_audit_config() {
    info "Creating immutable audit configuration..."
    
    cat > "${SCRIPT_DIR}/audit-config.yaml" << 'EOF'
# SovereignGuard Immutable Audit Configuration
# Addresses exposures: #9, #10, #22, #23, #27

name: sovereignguard-immutable-audit
version: "1.0.0"

# Audit log collection
collection:
  sources:
    - name: "vault"
      type: "file"
      path: "/var/log/vault/audit.log"
      format: "json"
      
    - name: "kubernetes"
      type: "kubernetes-audit"
      api_server: "https://kubernetes.default"
      
    - name: "discord-bot"
      type: "application"
      endpoint: "http://discord-ops-bot:3000/audit"
      
    - name: "event-gateway"
      type: "application"
      endpoint: "http://event-gateway:8080/audit"
      
    - name: "trading"
      type: "application"
      endpoint: "http://swarmgate:8443/audit"
      
    - name: "system"
      type: "syslog"
      socket: "/dev/log"

# Elasticsearch storage
storage:
  elasticsearch:
    hosts:
      - "elasticsearch:9200"
    index_prefix: "sovereignguard-audit"
    index_rotation: "daily"
    shards: 2
    replicas: 1
    
  # WORM (Write Once Read Many) settings
  worm:
    enabled: true
    retention_days: 2555  # 7 years
    delete_protection: true
    
  # Local backup
  backup:
    enabled: true
    path: "/var/backups/audit"
    rotation_days: 30
    compress: true

# Blockchain anchoring
blockchain:
  enabled: true
  provider: "opentimestamps"
  
  # Anchoring schedule
  schedule:
    interval_hours: 24
    anchor_on_shutdown: true
    
  # Bitcoin blockchain settings
  bitcoin:
    network: "mainnet"
    calendar_servers:
      - "https://alice.btc.calendar.opentimestamps.org"
      - "https://bob.btc.calendar.opentimestamps.org"
      - "https://finney.calendar.eternitywall.com"
      
  # Proof storage
  proofs:
    path: "/var/lib/sovereignguard/ots-proofs"
    backup_to_vault: true

# Security settings
security:
  # Log encryption
  encryption:
    enabled: true
    algorithm: "aes-256-gcm"
    key_source: "vault"
    
  # Tamper detection
  tamper_detection:
    enabled: true
    hash_algorithm: "sha256"
    merkle_tree: true
    
  # Access control
  access:
    read_roles: ["admin", "auditor", "compliance"]
    write_roles: ["system"]  # Only system can write

# Event types to audit
events:
  # Security events
  security:
    - "authentication_success"
    - "authentication_failure"
    - "authorization_failure"
    - "credential_access"
    - "secret_rotation"
    - "policy_change"
    
  # Financial events
  financial:
    - "trade_executed"
    - "trade_pending"
    - "trade_rejected"
    - "limit_exceeded"
    - "human_approval_requested"
    - "human_approval_granted"
    - "human_approval_denied"
    
  # System events
  system:
    - "service_start"
    - "service_stop"
    - "config_change"
    - "network_connection"
    - "resource_exhaustion"
    
  # Data events
  data:
    - "data_access"
    - "data_export"
    - "data_deletion"
    - "backup_created"
    - "backup_restored"

# Alerting
alerting:
  enabled: true
  
  rules:
    - name: "Multiple Auth Failures"
      condition: "authentication_failure > 5 in 5m"
      severity: "high"
      action: "discord_alert"
      
    - name: "Credential Access Outside Hours"
      condition: "credential_access AND (hour < 6 OR hour > 22)"
      severity: "medium"
      action: "log_and_alert"
      
    - name: "Large Transaction"
      condition: "trade_executed AND amount > 100"
      severity: "high"
      action: "discord_alert"
      
    - name: "Tamper Detected"
      condition: "tamper_detection_triggered"
      severity: "critical"
      action: "emergency_shutdown"
      
  destinations:
    discord_alert:
      webhook: "${DISCORD_SECURITY_WEBHOOK:-}"
      
    emergency_shutdown:
      webhook: "${DISCORD_SECURITY_WEBHOOK:-}"
      action: "systemctl stop sovereignguard"

# Retention and compliance
compliance:
  frameworks:
    - "SOC2"
    - "ISO27001"
    - "GDPR"
    
  retention:
    default_days: 2555  # 7 years
    financial_days: 2555  # 7 years (required by IRS)
    security_days: 1095  # 3 years
    
  reports:
    automated: true
    schedule: "0 6 1 * *"  # Monthly on 1st at 6 AM
    formats: ["pdf", "json"]
    recipients: ["compliance@example.com"]
EOF
    
    success "Audit configuration created"
}

# Create OpenTimestamps anchoring script
create_ots_anchoring() {
    info "Creating OpenTimestamps anchoring script..."
    
    cat > "${SCRIPT_DIR}/anchor-to-blockchain.sh" << 'EOF'
#!/bin/bash
# SovereignGuard - Blockchain Anchoring Script
# Anchors audit log hashes to Bitcoin blockchain via OpenTimestamps

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROOFS_DIR="${PROOFS_DIR:-/var/lib/sovereignguard/ots-proofs}"
AUDIT_INDEX="${AUDIT_INDEX:-sovereignguard-audit-$(date +%Y.%m.%d)}"
ES_HOST="${ES_HOST:-elasticsearch:9200}"

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

info() { echo -e "${BLUE}[INFO]${NC} $*"; }
warn() { echo -e "${YELLOW}[WARN]${NC} $*"; }
success() { echo -e "${GREEN}[SUCCESS]${NC} $*"; }

# Check for ots command
check_ots() {
    if ! command -v ots >/dev/null 2>&1; then
        warn "OpenTimestamps CLI not found. Installing..."
        pip3 install opentimestamps-client
    fi
}

# Export audit logs for the day
export_audit_logs() {
    local output_file="$1"
    
    info "Exporting audit logs from Elasticsearch..."
    
    # Export all documents from today's index
    curl -s -X GET "${ES_HOST}/${AUDIT_INDEX}/_search?size=10000" \
        -H "Content-Type: application/json" \
        -d '{"query": {"match_all": {}}}' \
        | jq -c '.hits.hits[]._source' > "$output_file"
        
    info "Exported $(wc -l < "$output_file") audit events"
}

# Create Merkle tree root hash
create_merkle_root() {
    local input_file="$1"
    local merkle_file="$2"
    
    info "Creating Merkle tree root hash..."
    
    # Hash each line and create Merkle tree
    local hashes=()
    while IFS= read -r line; do
        hash=$(echo -n "$line" | sha256sum | cut -d' ' -f1)
        hashes+=("$hash")
    done < "$input_file"
    
    # Simple Merkle tree (for production, use proper implementation)
    local combined=""
    for hash in "${hashes[@]}"; do
        combined="${combined}${hash}"
    done
    
    local root_hash
    root_hash=$(echo -n "$combined" | sha256sum | cut -d' ' -f1)
    
    # Save Merkle proof file
    cat > "$merkle_file" << MERKLE
{
  "date": "$(date -Iseconds)",
  "index": "${AUDIT_INDEX}",
  "event_count": ${#hashes[@]},
  "merkle_root": "${root_hash}",
  "algorithm": "sha256"
}
MERKLE
    
    echo "$root_hash"
}

# Anchor to Bitcoin blockchain
anchor_to_blockchain() {
    local merkle_file="$1"
    local proof_file="$2"
    
    info "Anchoring to Bitcoin blockchain via OpenTimestamps..."
    
    # Create timestamp
    ots stamp "$merkle_file"
    
    # The .ots file is created automatically
    if [[ -f "${merkle_file}.ots" ]]; then
        mv "${merkle_file}.ots" "$proof_file"
        success "Blockchain anchor created: $proof_file"
    else
        warn "OpenTimestamps proof file not created"
        return 1
    fi
}

# Upgrade pending proofs
upgrade_proofs() {
    info "Upgrading pending proofs..."
    
    find "$PROOFS_DIR" -name "*.ots" -type f | while read -r proof; do
        info "Upgrading: $proof"
        ots upgrade "$proof" 2>/dev/null || true
    done
}

# Verify existing proofs
verify_proofs() {
    info "Verifying existing proofs..."
    
    find "$PROOFS_DIR" -name "*.ots" -type f | while read -r proof; do
        merkle_file="${proof%.ots}"
        if [[ -f "$merkle_file" ]]; then
            if ots verify "$proof" 2>/dev/null; then
                success "Verified: $proof"
            else
                warn "Pending verification: $proof"
            fi
        fi
    done
}

# Main execution
main() {
    local date_str
    date_str=$(date +%Y-%m-%d)
    
    mkdir -p "$PROOFS_DIR"
    
    check_ots
    
    # Export and anchor today's logs
    local audit_file="${PROOFS_DIR}/audit-${date_str}.json"
    local merkle_file="${PROOFS_DIR}/merkle-${date_str}.json"
    local proof_file="${PROOFS_DIR}/proof-${date_str}.ots"
    
    export_audit_logs "$audit_file"
    
    if [[ -s "$audit_file" ]]; then
        create_merkle_root "$audit_file" "$merkle_file"
        anchor_to_blockchain "$merkle_file" "$proof_file"
        
        # Clean up raw audit export (keep Merkle proof)
        rm -f "$audit_file"
    else
        warn "No audit events to anchor for ${date_str}"
    fi
    
    # Upgrade and verify existing proofs
    upgrade_proofs
    verify_proofs
    
    success "Blockchain anchoring complete"
}

# Execute if run directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
EOF
    
    chmod +x "${SCRIPT_DIR}/anchor-to-blockchain.sh"
    success "Blockchain anchoring script created"
}

# Create Elasticsearch index template
create_es_template() {
    info "Creating Elasticsearch index template..."
    
    cat > "${SCRIPT_DIR}/elasticsearch-template.json" << 'EOF'
{
  "index_patterns": ["sovereignguard-audit-*"],
  "settings": {
    "number_of_shards": 2,
    "number_of_replicas": 1,
    "index.lifecycle.name": "sovereignguard-audit-policy",
    "index.lifecycle.rollover_alias": "sovereignguard-audit",
    "index.blocks.read_only_allow_delete": null
  },
  "mappings": {
    "properties": {
      "@timestamp": {
        "type": "date"
      },
      "event_id": {
        "type": "keyword"
      },
      "event_type": {
        "type": "keyword"
      },
      "category": {
        "type": "keyword"
      },
      "severity": {
        "type": "keyword"
      },
      "source": {
        "type": "keyword"
      },
      "actor": {
        "type": "object",
        "properties": {
          "id": {"type": "keyword"},
          "name": {"type": "keyword"},
          "type": {"type": "keyword"},
          "ip": {"type": "ip"}
        }
      },
      "target": {
        "type": "object",
        "properties": {
          "id": {"type": "keyword"},
          "name": {"type": "keyword"},
          "type": {"type": "keyword"}
        }
      },
      "action": {
        "type": "keyword"
      },
      "outcome": {
        "type": "keyword"
      },
      "message": {
        "type": "text"
      },
      "metadata": {
        "type": "object",
        "enabled": true,
        "dynamic": true
      },
      "hash": {
        "type": "keyword"
      },
      "previous_hash": {
        "type": "keyword"
      },
      "blockchain_anchor": {
        "type": "object",
        "properties": {
          "anchored": {"type": "boolean"},
          "anchor_date": {"type": "date"},
          "proof_file": {"type": "keyword"},
          "bitcoin_block": {"type": "long"}
        }
      }
    }
  }
}
EOF
    
    success "Elasticsearch template created"
}

# Create ILM policy for log retention
create_ilm_policy() {
    info "Creating ILM policy..."
    
    cat > "${SCRIPT_DIR}/ilm-policy.json" << 'EOF'
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_age": "1d",
            "max_size": "10gb"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "shrink": {
            "number_of_shards": 1
          },
          "forcemerge": {
            "max_num_segments": 1
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "freeze": {}
        }
      },
      "delete": {
        "min_age": "2555d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
EOF
    
    success "ILM policy created"
}

# Create audit event logger
create_audit_logger() {
    info "Creating audit event logger..."
    
    cat > "${SCRIPT_DIR}/audit_logger.py" << 'EOF'
#!/usr/bin/env python3
"""
SovereignGuard Immutable Audit Logger
Addresses exposures: #9, #10, #22, #23, #27

This module provides secure, tamper-evident audit logging.
"""

import hashlib
import json
import logging
import os
import uuid
from dataclasses import asdict, dataclass
from datetime import datetime
from typing import Any, Optional

import requests

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('sovereignguard.audit')


@dataclass
class Actor:
    """Represents the entity performing an action"""
    id: str
    name: str
    type: str  # user, service, system
    ip: Optional[str] = None


@dataclass
class Target:
    """Represents the target of an action"""
    id: str
    name: str
    type: str  # resource, secret, api, etc.


@dataclass
class AuditEvent:
    """Represents an immutable audit event"""
    event_id: str
    event_type: str
    category: str  # security, financial, system, data
    severity: str  # low, medium, high, critical
    source: str
    actor: Actor
    target: Target
    action: str
    outcome: str  # success, failure, pending
    message: str
    timestamp: str
    metadata: dict
    hash: str
    previous_hash: str


class AuditLogger:
    """
    Tamper-evident audit logger with blockchain anchoring support.
    
    Features:
    - Hash chaining for tamper detection
    - Automatic Elasticsearch indexing
    - Discord alerting for critical events
    - Blockchain anchoring via OpenTimestamps
    """
    
    def __init__(
        self,
        es_host: str = "elasticsearch:9200",
        index_prefix: str = "sovereignguard-audit",
        discord_webhook: Optional[str] = None
    ):
        self.es_host = es_host
        self.index_prefix = index_prefix
        self.discord_webhook = discord_webhook
        self._previous_hash = "genesis"
        
    def _compute_hash(self, event: AuditEvent) -> str:
        """Compute SHA-256 hash of the event"""
        # Exclude hash fields from computation
        data = {
            "event_id": event.event_id,
            "event_type": event.event_type,
            "category": event.category,
            "severity": event.severity,
            "source": event.source,
            "actor": asdict(event.actor),
            "target": asdict(event.target),
            "action": event.action,
            "outcome": event.outcome,
            "message": event.message,
            "timestamp": event.timestamp,
            "metadata": event.metadata,
            "previous_hash": event.previous_hash
        }
        return hashlib.sha256(json.dumps(data, sort_keys=True).encode()).hexdigest()
        
    def _get_index_name(self) -> str:
        """Get the current index name based on date"""
        return f"{self.index_prefix}-{datetime.now().strftime('%Y.%m.%d')}"
        
    def _send_to_elasticsearch(self, event: AuditEvent) -> bool:
        """
        Send event to Elasticsearch with explicit SSL configuration.
        
        Security note: In production, configure proper CA certificates.
        Set ES_CA_CERT environment variable to CA certificate path.
        """
        try:
            # Determine SSL verification settings
            es_ca_cert = os.environ.get('ES_CA_CERT')
            verify_ssl = es_ca_cert if es_ca_cert else True
            
            # Use HTTPS if configured, otherwise HTTP for local development
            protocol = "https" if os.environ.get('ES_USE_SSL', 'false').lower() == 'true' else "http"
            
            response = requests.post(
                f"{protocol}://{self.es_host}/{self._get_index_name()}/_doc",
                json=asdict(event),
                headers={"Content-Type": "application/json"},
                timeout=5,
                verify=verify_ssl
            )
            return response.status_code in [200, 201]
        except requests.exceptions.SSLError as e:
            logger.error(f"SSL verification failed for Elasticsearch: {e}")
            return False
        except Exception as e:
            logger.error(f"Failed to send to Elasticsearch: {e}")
            return False
            
    def _send_discord_alert(self, event: AuditEvent) -> None:
        """
        Send critical events to Discord with SSL verification.
        
        Security note: Discord webhooks use HTTPS by default with proper
        certificate verification enabled.
        """
        if not self.discord_webhook:
            return
            
        if event.severity not in ["high", "critical"]:
            return
            
        try:
            payload = {
                "embeds": [{
                    "title": f"ðŸš¨ Security Alert: {event.event_type}",
                    "description": event.message,
                    "color": 0xFF0000 if event.severity == "critical" else 0xFFA500,
                    "fields": [
                        {"name": "Severity", "value": event.severity, "inline": True},
                        {"name": "Category", "value": event.category, "inline": True},
                        {"name": "Outcome", "value": event.outcome, "inline": True},
                        {"name": "Actor", "value": f"{event.actor.name} ({event.actor.type})", "inline": True},
                        {"name": "Target", "value": f"{event.target.name} ({event.target.type})", "inline": True},
                        {"name": "Event ID", "value": event.event_id, "inline": False}
                    ],
                    "timestamp": event.timestamp
                }]
            }
            
            requests.post(
                self.discord_webhook,
                json=payload,
                timeout=5
            )
        except Exception as e:
            logger.error(f"Failed to send Discord alert: {e}")
            
    def log_event(
        self,
        event_type: str,
        category: str,
        severity: str,
        source: str,
        actor: Actor,
        target: Target,
        action: str,
        outcome: str,
        message: str,
        metadata: Optional[dict] = None
    ) -> AuditEvent:
        """
        Log an audit event with tamper-evident hash chaining.
        
        Args:
            event_type: Type of event (e.g., 'authentication_failure')
            category: Event category (security, financial, system, data)
            severity: Event severity (low, medium, high, critical)
            source: Source service/component
            actor: Entity performing the action
            target: Target of the action
            action: Action performed
            outcome: Result of the action
            message: Human-readable description
            metadata: Additional event data
            
        Returns:
            The logged AuditEvent
        """
        event = AuditEvent(
            event_id=str(uuid.uuid4()),
            event_type=event_type,
            category=category,
            severity=severity,
            source=source,
            actor=actor,
            target=target,
            action=action,
            outcome=outcome,
            message=message,
            timestamp=datetime.utcnow().isoformat() + "Z",
            metadata=metadata or {},
            hash="",
            previous_hash=self._previous_hash
        )
        
        # Compute hash
        event.hash = self._compute_hash(event)
        self._previous_hash = event.hash
        
        # Log locally
        logger.info(f"AUDIT: {event.event_type} - {event.message} (hash: {event.hash[:16]}...)")
        
        # Send to Elasticsearch
        self._send_to_elasticsearch(event)
        
        # Send Discord alert if needed
        self._send_discord_alert(event)
        
        return event
        
    def verify_chain(self, events: list) -> bool:
        """Verify the integrity of a chain of events"""
        if not events:
            return True
            
        for i, event_data in enumerate(events):
            event = AuditEvent(**event_data)
            
            # Verify hash
            computed_hash = self._compute_hash(event)
            if computed_hash != event.hash:
                logger.error(f"Hash mismatch at event {event.event_id}")
                return False
                
            # Verify chain
            if i > 0:
                if event.previous_hash != events[i-1]["hash"]:
                    logger.error(f"Chain broken at event {event.event_id}")
                    return False
                    
        return True


# Convenience functions for common audit events
def log_auth_success(logger: AuditLogger, actor: Actor, method: str) -> AuditEvent:
    """Log successful authentication"""
    return logger.log_event(
        event_type="authentication_success",
        category="security",
        severity="low",
        source="auth",
        actor=actor,
        target=Target(id="auth-service", name="Authentication", type="service"),
        action="authenticate",
        outcome="success",
        message=f"User {actor.name} authenticated successfully via {method}"
    )


def log_auth_failure(logger: AuditLogger, actor: Actor, method: str, reason: str) -> AuditEvent:
    """Log failed authentication"""
    return logger.log_event(
        event_type="authentication_failure",
        category="security",
        severity="medium",
        source="auth",
        actor=actor,
        target=Target(id="auth-service", name="Authentication", type="service"),
        action="authenticate",
        outcome="failure",
        message=f"Authentication failed for {actor.name} via {method}: {reason}"
    )


def log_trade_executed(
    logger: AuditLogger,
    actor: Actor,
    broker: str,
    symbol: str,
    action: str,
    amount: float
) -> AuditEvent:
    """Log executed trade"""
    return logger.log_event(
        event_type="trade_executed",
        category="financial",
        severity="high" if amount > 50 else "medium",
        source="trading",
        actor=actor,
        target=Target(id=broker, name=broker, type="broker"),
        action=action,
        outcome="success",
        message=f"Trade executed: {action} ${amount} of {symbol} via {broker}",
        metadata={"symbol": symbol, "amount": amount, "broker": broker}
    )


if __name__ == "__main__":
    # Example usage
    audit = AuditLogger(
        es_host=os.environ.get("ES_HOST", "localhost:9200"),
        discord_webhook=os.environ.get("DISCORD_SECURITY_WEBHOOK")
    )
    
    # Log example event
    actor = Actor(id="user-1", name="admin", type="user", ip="192.168.1.1")
    event = log_auth_success(audit, actor, "password")
    print(f"Logged event: {event.event_id}")
EOF
    
    chmod +x "${SCRIPT_DIR}/audit_logger.py"
    success "Audit logger created"
}

# Print setup summary
print_summary() {
    echo ""
    echo "=========================================="
    echo "ðŸ“‹ Immutable Audit Setup Summary"
    echo "=========================================="
    echo ""
    echo "Configuration Files Created:"
    echo "  - ${SCRIPT_DIR}/audit-config.yaml"
    echo "  - ${SCRIPT_DIR}/anchor-to-blockchain.sh"
    echo "  - ${SCRIPT_DIR}/elasticsearch-template.json"
    echo "  - ${SCRIPT_DIR}/ilm-policy.json"
    echo "  - ${SCRIPT_DIR}/audit_logger.py"
    echo ""
    echo "Security Features:"
    echo "  âœ“ Hash chaining for tamper detection"
    echo "  âœ“ Merkle tree proof generation"
    echo "  âœ“ Bitcoin blockchain anchoring"
    echo "  âœ“ 7-year retention (IRS compliant)"
    echo "  âœ“ WORM storage protection"
    echo "  âœ“ Discord alerting for critical events"
    echo ""
    echo "Exposures Addressed:"
    echo "  #9 - Gmail OAuth/Drive/Obsidian chain"
    echo "  #10 - Starlink IP exposure/enumeration"
    echo "  #22 - Browser extension keylogging"
    echo "  #23 - Obsidian plugin backdoor"
    echo "  #27 - 501(c)(3) legal liability"
    echo ""
    echo "Next Steps:"
    echo "  1. Deploy Elasticsearch cluster"
    echo "  2. Apply index template and ILM policy"
    echo "  3. Install OpenTimestamps CLI"
    echo "  4. Configure cron for daily anchoring"
    echo "  5. Set up Discord webhook"
    echo ""
}

# Main execution
main() {
    echo ""
    echo "=========================================="
    echo "ðŸ“‹ SovereignGuard Immutable Audit Setup"
    echo "   Phase 5: Blockchain-Anchored Logs"
    echo "   Addresses exposures: #9, #10, #22, #23, #27"
    echo "=========================================="
    echo ""
    
    create_audit_config
    create_ots_anchoring
    create_es_template
    create_ilm_policy
    create_audit_logger
    print_summary
    
    success "=========================================="
    success "ðŸŽ‰ Immutable audit setup complete!"
    success "=========================================="
}

# Execute if run directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
